{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import discrepancy, visualization\n",
    "from algorithms import ABC_algorithms, TPABC, SMCABC, SMC2ABC, SNLABC, SNL2ABC\n",
    "from problems import problem_IS\n",
    "\n",
    "import utils_os, utils_math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sampling from true posterior ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIR = 'results/IS'                                             \n",
    "RERUN = not utils_os.is_file_exist(DIR, 'true_samples.npy') \n",
    "\n",
    "## Define the problem\n",
    "problem = problem_IS.IS_Problem(N=500, n=1)\n",
    "true_theta = problem.get_true_theta()\n",
    "\n",
    "## Get x_o ~ p(x|theta)\n",
    "if RERUN:\n",
    "    # observed data x_o\n",
    "    problem.data_obs = problem.simulator(true_theta)\n",
    "    problem.y_obs = problem.statistics(data=problem.data_obs)\n",
    "    utils_os.save_object(DIR, 'data_obs', problem.data_obs)\n",
    "    utils_os.save_object(DIR, 'y_obs', problem.y_obs)\n",
    "else:\n",
    "    problem.data_obs  = utils_os.load_object(DIR, 'data_obs.npy')\n",
    "    problem.y_obs  = problem.statistics(data=problem.data_obs)\n",
    "    \n",
    "\n",
    "## Get True posterior (rejection sampling approximation with 1D sufficient stat)\n",
    "print('\\n sampling from true posterior ... \\n')\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.num_sim = 40000\n",
    "hyperparams.num_samples = 150\n",
    "hyperparams.device = 'cuda:3'\n",
    "hyperparams.L = 1\n",
    "tp_abc = TPABC.TP_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "if RERUN:\n",
    "    tp_abc.run()\n",
    "    true_samples = tp_abc.rej_samples\n",
    "    utils_os.save_object(DIR, 'true_samples', true_samples)\n",
    "else:\n",
    "    tp_abc = utils_os.load_algorithm(DIR, tp_abc)\n",
    "    true_samples = utils_os.load_object(DIR, 'true_samples.npy')\n",
    "    \n",
    "## Visualize\n",
    "# problem.visualize()  \n",
    "# visualization.plot_likelihood(samples=true_samples, log_likelihood_function=tp_abc.log_likelihood)\n",
    "# plt.savefig('IS_true_posterior.png')\n",
    "\n",
    "## Error - in log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMC-ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "# of cpus =  4\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start![ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "\n",
      "[sampling] finished sampling  50\n",
      "[sampling] finished sampling  100\n",
      "[sampling] finished sampling  150\n",
      "[sampling] finished sampling  200\n",
      "> learning fake posterior \n",
      "> learning true posterior \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cov must be 2 dimensional and square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5491/153203662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msmc_abc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMCABC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSMC_ABC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrepancy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscrepancy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meculidean_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msmc_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mJSD_smc_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/work/git/python/others/neural-approx-ss-lfi/algorithms/SMCABC.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_fake_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_true_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_true_posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/work/git/python/others/neural-approx-ss-lfi/algorithms/SMCABC.py\u001b[0m in \u001b[0;36mlearn_true_posterior\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mlog_weight_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_posterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mpdf_fake_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf_fake_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mlog_weight_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_fake_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/work/git/python/others/neural-approx-ss-lfi/algorithms/SMCABC.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, distribution)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Gaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_nd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Copula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/work/git/python/others/neural-approx-ss-lfi/distributions.py\u001b[0m in \u001b[0;36mdraw_samples\u001b[0;34m(mean, cov, N)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m#return stats.multivariate_normal.rvs(mean, cov, N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cov must be 2 dimensional and square"
     ]
    }
   ],
   "source": [
    "## Sequential Monte Carlo ABC\n",
    "\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:0'\n",
    "hyperparams.num_sim = 2000                        # number of simulations\n",
    "hyperparams.num_samples = 150                     # number of samples to represent posterior\n",
    "hyperparams.L = 2                                 # number of rounds in sequential learning\n",
    "\n",
    "smc_abc = SMCABC.SMC_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "smc_abc.run()\n",
    "\n",
    "JSD_smc_array = []\n",
    "for l in range(hyperparams.L):\n",
    "    print('round =', l)\n",
    "    smc_abc.posterior = smc_abc.posterior_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=smc_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, smc_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_smc_array.append(JSD)\n",
    "    print('JSD smc = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SMC', JSD_smc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential Monte Carlo ABC +\n",
    "\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:1'\n",
    "hyperparams.num_sim = 2000                       # number of simulations\n",
    "hyperparams.num_samples = 150                    # number of samples to represent posterior\n",
    "hyperparams.L = 2                                # number of learning rounds\n",
    "hyperparams.hidden_ratio = 0.05                  # dimensionality of S(x)\n",
    "hyperparams.type = 'cnn2d'                       # the network architecture of S(x), use CNN here\n",
    "hyperparams.estimator = 'JSD'                    # MI estimator; JSD or DC, see the paper\n",
    "\n",
    "smc2_abc = SMC2ABC.SMC2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "smc2_abc.run()\n",
    "\n",
    "JSD_smc2_array = []\n",
    "for l in range(len(smc2_abc.posterior_array)):\n",
    "    print('l=', l)\n",
    "    smc2_abc.l = l\n",
    "    smc2_abc.posterior = smc2_abc.posterior_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=smc2_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, smc2_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_smc2_array.append(JSD)\n",
    "    print('JSD smc2 = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SMC2', JSD_smc2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential Neural Likelihood\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:1'\n",
    "hyperparams.num_sim = 4000\n",
    "hyperparams.L = 2\n",
    "\n",
    "print('\\n SNL ABC')\n",
    "snl_abc = SNLABC.SNL_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "snl_abc.run()\n",
    "\n",
    "JSD_array = []\n",
    "for l in range(len(snl_abc.nde_array)):\n",
    "    print('l=', l)\n",
    "    snl_abc.nde_net = snl_abc.nde_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=snl_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, snl_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_array.append(JSD)\n",
    "    print('JSD snl = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SNL', JSD_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential Neural Likelihood + \n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:1'\n",
    "hyperparams.num_sim = 4000                       # number of simulations\n",
    "hyperparams.L = 2                                # number of learning rounds\n",
    "hyperparams.hidden_ratio = 0.05                  # dimensionality of S(x)\n",
    "hyperparams.type = 'plain'                       # the network architecture of S(x), use CNN here\n",
    "hyperparams.estimator = 'JSD'                    # MI estimator; JSD or DC, see the paper\n",
    "hyperparams.nde = 'MDN'                          # nde; MAF (D>1) or MDN (D=1)\n",
    "\n",
    "snl2_abc = SNL2ABC.SNL2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "snl2_abc.run()\n",
    "\n",
    "JSD_array = []\n",
    "for l in range(len(snl2_abc.nde_array)):\n",
    "    print('l=', l)\n",
    "    snl2_abc.set(l=l)\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=snl2_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, snl2_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_array.append(JSD)\n",
    "    print('JSD snl+ = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SNL2', JSD_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
